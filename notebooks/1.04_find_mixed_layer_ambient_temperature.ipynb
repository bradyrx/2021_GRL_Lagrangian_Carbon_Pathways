{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.04 Find Mixed Layer Ambient Temperature\n",
    "\n",
    "---\n",
    "\n",
    "Author : Riley X. Brady\n",
    "\n",
    "Date : 11/19/20\n",
    "\n",
    "Here we find the ambient mixed layer temperature for each particle in a given ensemble. To do this, we look at *in situ* particle temperature when it first enters 200 m after its last 1000 m crossing. This ambient temperature is used to calculate potential pCO$_{2}$, the pCO$_{2}$ the particle would have if brought to the point at which it upwells into the mixed layer, due to thermal effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import gsw\n",
    "\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.19.4\n",
      "xarray: 0.16.1\n",
      "gsw: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"xarray: {xr.__version__}\")\n",
    "print(f\"gsw: {gsw.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is my TCP client from the `launch_cluster` notebook. I use it\n",
    "# for distributed computing with `dask` on NCAR's machine, Casper.\n",
    "client = Client(\"tcp://...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: I loaded in the netCDF file, and chunked it, and then saved it back out as a `zarr` file. This makes `dask` run a lot more efficiently. E.g.,\n",
    "\n",
    "```python\n",
    "ds = xr.open_dataset('../data/southern_ocean_deep_upwelling_particles.nc')\n",
    "ds = ds.chunk({'time': -1, 'nParticles': 'auto'})\n",
    "ds.to_zarr('../data/southern_ocean_deep_upwelling_particles.zarr', consolidated=True)\n",
    "```\n",
    "\n",
    "You could probably chunk the particles into slightly smaller chunks for even faster performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the `zarr` file, which is pre-chunked and already has been\n",
    "# filtered from the original 1,000,000 particles to the 19,002 that\n",
    "# upwell last across 1000 m S of 45S and outside of the annual sea ice\n",
    "# edge.\n",
    "filepath = \"../data/southern_ocean_deep_upwelling_particles.zarr/\"\n",
    "ds = xr.open_zarr(filepath, consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idx_of_last_1000m_crossing(z):\n",
    "    \"\"\"Find index of final time particle upwells across 1000 m.\n",
    "\n",
    "    z : zLevelParticle\n",
    "    \"\"\"\n",
    "    currentDepth = z\n",
    "    previousDepth = np.roll(z, 1)\n",
    "    previousDepth[0] = 999  # So we're not dealing with a nan here.\n",
    "    cond = (currentDepth >= -1000) & (previousDepth < -1000)\n",
    "    idx = (\n",
    "        len(cond) - np.flip(cond).argmax() - 1\n",
    "    )  # Finds last location that condition is true.\n",
    "    return idx\n",
    "\n",
    "\n",
    "def compute_idx_of_first_200m_crossing(z):\n",
    "    \"\"\"Find first time particle upwells across 200 m.\n",
    "\n",
    "    z : zLevelParticle\n",
    "    \"\"\"\n",
    "    currentDepth = z\n",
    "    previousDepth = np.roll(z, 1)\n",
    "    previousDepth[0] = 999\n",
    "    cond = (currentDepth >= -200) & (previousDepth < -200)\n",
    "    idx = cond.argmax()\n",
    "    return idx\n",
    "\n",
    "\n",
    "def find_200m_ambient_temperature(z, t):\n",
    "    \"\"\"\n",
    "    Finds the ambient temperature at the 200m crossing point.\n",
    "    \"\"\"\n",
    "    idx_a = compute_idx_of_last_1000m_crossing(z)\n",
    "    z_subset = z[idx_a::]\n",
    "    idx_b = compute_idx_of_first_200m_crossing(z_subset)\n",
    "    return t[idx_a + idx_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ambient temperature for each ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drake...\n",
      "CPU times: user 11.1 ms, sys: 4.05 ms, total: 15.2 ms\n",
      "Wall time: 2.71 s\n",
      "Saving to netCDF...\n",
      "crozet...\n",
      "CPU times: user 16.3 ms, sys: 715 µs, total: 17 ms\n",
      "Wall time: 4.62 s\n",
      "Saving to netCDF...\n",
      "campbell...\n",
      "CPU times: user 14.6 ms, sys: 179 µs, total: 14.7 ms\n",
      "Wall time: 2.22 s\n",
      "Saving to netCDF...\n",
      "kerguelan...\n",
      "CPU times: user 14.6 ms, sys: 0 ns, total: 14.6 ms\n",
      "Wall time: 1.87 s\n",
      "Saving to netCDF...\n",
      "non_topographic...\n",
      "CPU times: user 14.2 ms, sys: 1.07 ms, total: 15.3 ms\n",
      "Wall time: 2.65 s\n",
      "Saving to netCDF...\n"
     ]
    }
   ],
   "source": [
    "for region_name in [\"drake\", \"crozet\", \"campbell\", \"kerguelan\", \"non_topographic\"]:\n",
    "    print(f\"{region_name}...\")\n",
    "    # Load in ensemble for given region to get particle IDs.\n",
    "    ensemble_ids = xr.open_dataset(\n",
    "        f\"../data/postproc/{region_name}.1000m.tracer.origin.nc\"\n",
    "    )\n",
    "    ensemble = ds.sel(nParticles=ensemble_ids.nParticles)\n",
    "\n",
    "    # Calculate in situ temperature, since the particle temperature is actually\n",
    "    # potential temperature.\n",
    "    ensemble[\"t_insitu\"] = gsw.pt_from_t(\n",
    "        ensemble.particleSalinity,\n",
    "        ensemble.particleTemperature,\n",
    "        0,\n",
    "        ensemble.zLevelParticle * -1,\n",
    "    )\n",
    "\n",
    "    # Calculate ambient temperature for the given ensemble.\n",
    "    ambient = xr.apply_ufunc(\n",
    "        find_200m_ambient_temperature,\n",
    "        ensemble.zLevelParticle,\n",
    "        ensemble.t_insitu,\n",
    "        input_core_dims=[[\"time\"], [\"time\"]],\n",
    "        dask=\"parallelized\",\n",
    "        vectorize=True,\n",
    "        output_dtypes=[float],\n",
    "        dask_gufunc_kwargs={\"allow_rechunk\": True},\n",
    "    )\n",
    "    %time ambient = ambient.compute()\n",
    "\n",
    "    print(\"Saving to netCDF...\")\n",
    "    ds_out = ambient.rename(\"T_ambient\").to_dataset()\n",
    "    ds_out.attrs[\n",
    "        \"description\"\n",
    "    ] = \"in situ particle temperature when particle first enters mixed layer (200 m) after its last 1000 m crossing.\"\n",
    "    ds_out.to_netcdf(f\"../data/postproc/{region_name}.ambient.temperature.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-brady-carbonpathways]",
   "language": "python",
   "name": "conda-env-miniconda3-brady-carbonpathways-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
